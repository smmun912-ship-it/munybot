"""
ì¢…í•© ì—ì´ì „íŠ¸: ë¦¬ì„œì¹˜ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ NotebookLMì— ì „ë‹¬í•˜ê³  ì½˜í…ì¸  ìƒì„±
- ì±„ë„ë³„ ìš”ì•½ì„ í•˜ë‚˜ì˜ ì¢…í•© ë³´ê³ ì„œë¡œ í†µí•©
- Gemini APIë¡œ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
- ìŠ¬ë¼ì´ë“œ/ì¸í¬ê·¸ë˜í”½ ë°ì´í„° êµ¬ì¡°í™”
"""
import json
import logging
from datetime import datetime
from pathlib import Path

try:
    import google.generativeai as genai
    HAS_GEMINI = True
except ImportError:
    HAS_GEMINI = False

from config import GEMINI_API_KEY, GEMINI_MODEL, get_today_output_dir

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Gemini API ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def init_gemini():
    """Gemini API ì´ˆê¸°í™”"""
    if not HAS_GEMINI:
        logger.warning("âš ï¸ google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    if not GEMINI_API_KEY:
        logger.warning("âš ï¸ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    genai.configure(api_key=GEMINI_API_KEY)
    return genai.GenerativeModel(GEMINI_MODEL)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_combined_summary(output_dir: Path) -> str:
    """ëª¨ë“  ì±„ë„ ìš”ì•½ì„ í•˜ë‚˜ì˜ ì¢…í•© ë³´ê³ ì„œë¡œ í†µí•©í•©ë‹ˆë‹¤."""
    summary_dir = output_dir / "channel_summaries"
    if not summary_dir.exists():
        logger.error("âŒ ì±„ë„ ìš”ì•½ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return ""

    summaries = []
    for md_file in sorted(summary_dir.glob("*.md")):
        content = md_file.read_text(encoding="utf-8")
        if content.strip():
            summaries.append(content)

    if not summaries:
        logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ì±„ë„ ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")
        return ""

    combined = f"""# ğŸ“Š AI/í…Œí¬ ìœ íŠœë¸Œ ì¼ì¼ ì¢…í•© ë³´ê³ ì„œ

**ìƒì„±ì¼**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}
**ë¶„ì„ ëŒ€ìƒ**: {len(summaries)}ê°œ ì±„ë„

---

"""
    combined += "\n\n---\n\n".join(summaries)

    # ì¢…í•© ë³´ê³ ì„œ ì €ì¥
    combined_path = output_dir / "combined_summary.md"
    combined_path.write_text(combined, encoding="utf-8")
    logger.info(f"ğŸ“„ ì¢…í•© ë³´ê³ ì„œ ì €ì¥: {combined_path}")

    return combined


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PODCAST_PROMPT = """ë‹¹ì‹ ì€ AI/í…Œí¬ ë¶„ì•¼ì˜ ì¸ê¸° íŒŸìºìŠ¤íŠ¸ ì§„í–‰ìì…ë‹ˆë‹¤.
ì•„ë˜ ì—¬ëŸ¬ ìœ íŠœë¸Œ ì±„ë„ì˜ ìµœì‹  ì˜ìƒ ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ,
ë‘ ëª…ì˜ ì§„í–‰ì(í˜¸ìŠ¤íŠ¸A, í˜¸ìŠ¤íŠ¸B)ê°€ ëŒ€í™”í•˜ëŠ” í˜•ì‹ì˜ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**í˜•ì‹ ìš”êµ¬ì‚¬í•­:**
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ (í•œêµ­ì–´)
- í˜¸ìŠ¤íŠ¸AëŠ” ë©”ì¸ ì§„í–‰ì, í˜¸ìŠ¤íŠ¸BëŠ” ë¶„ì„ê°€ ì—­í• 
- ì˜¤í”„ë‹ ì¸ì‚¬ â†’ ì£¼ìš” ë‰´ìŠ¤/íŠ¸ë Œë“œ ì†Œê°œ â†’ ì‹¬ì¸µ ë¶„ì„ â†’ í´ë¡œì§•
- ê° ì±„ë„ì˜ í•µì‹¬ ì½˜í…ì¸ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—®ì–´ì„œ ì´ì•¼ê¸°
- ì²­ì·¨ìê°€ í¥ë¯¸ë¥¼ ëŠë‚„ ìˆ˜ ìˆëŠ” í¬ì¸íŠ¸ ê°•ì¡°
- 15~20ë¶„ ë¶„ëŸ‰ (ì•½ 3000~4000ì)

**ëŒ€í™” í˜•ì‹:**
í˜¸ìŠ¤íŠ¸A: (ëŒ€ì‚¬)
í˜¸ìŠ¤íŠ¸B: (ëŒ€ì‚¬)

ì•„ë˜ëŠ” ì˜¤ëŠ˜ì˜ ìœ íŠœë¸Œ ì±„ë„ ìš”ì•½ì…ë‹ˆë‹¤:

{content}
"""


def generate_podcast_script(combined_summary: str, model) -> str:
    """Geminië¥¼ ì‚¬ìš©í•˜ì—¬ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    logger.info("ğŸ™ï¸ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...")

    if model is None:
        return _generate_podcast_fallback(combined_summary)

    try:
        prompt = PODCAST_PROMPT.format(content=combined_summary[:30000])
        response = model.generate_content(prompt)
        script = response.text
        logger.info(f"  âœ… íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ ({len(script)}ì)")
        return script
    except Exception as e:
        logger.error(f"  âŒ Gemini API ì˜¤ë¥˜: {e}")
        return _generate_podcast_fallback(combined_summary)


def _generate_podcast_fallback(combined_summary: str) -> str:
    """Gemini API ì—†ì´ ê¸°ë³¸ íŒŸìºìŠ¤íŠ¸ í…œí”Œë¦¿ ìƒì„±"""
    logger.info("  â„¹ï¸ í´ë°± ëª¨ë“œ: ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
    return f"""# ğŸ™ï¸ AI/í…Œí¬ ë°ì¼ë¦¬ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

**ë‚ ì§œ**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼')}

---

í˜¸ìŠ¤íŠ¸A: ì•ˆë…•í•˜ì„¸ìš”! AI/í…Œí¬ ë°ì¼ë¦¬ íŒŸìºìŠ¤íŠ¸ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.
í˜¸ìŠ¤íŠ¸B: ë„¤, ì˜¤ëŠ˜ë„ ì—¬ëŸ¬ AI ìœ íŠœë²„ë“¤ì˜ ìµœì‹  ì½˜í…ì¸ ë¥¼ ì¢…í•©í•´ì„œ ì „í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

í˜¸ìŠ¤íŠ¸A: ì˜¤ëŠ˜ì€ ì´ ì—¬ëŸ¬ ì±„ë„ì—ì„œ ìƒˆë¡œìš´ ì˜ìƒì´ ì˜¬ë¼ì™”ëŠ”ë°ìš”,
ì£¼ìš” ë‚´ìš©ì„ ì •ë¦¬í•´ë³¼ê¹Œìš”?

---

> âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ìë™ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
> ì•„ë˜ ì¢…í•© ìš”ì•½ì„ ì°¸ê³ í•˜ì—¬ ì§ì ‘ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ê±°ë‚˜,
> GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.

---

## ì›ë³¸ ì¢…í•© ìš”ì•½

{combined_summary[:5000]}
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ìŠ¬ë¼ì´ë“œ ë°ì´í„° ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SLIDES_PROMPT = """ì•„ë˜ ìœ íŠœë¸Œ ì±„ë„ ì¢…í•© ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ, í”„ë ˆì  í…Œì´ì…˜ ìŠ¬ë¼ì´ë“œ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- ì´ 8~12ì¥ ìŠ¬ë¼ì´ë“œ
- ê° ìŠ¬ë¼ì´ë“œì—ëŠ” title, content (ë¶ˆë¦¿í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸), notes (ë°œí‘œì ë…¸íŠ¸) í¬í•¨
- ì²« ìŠ¬ë¼ì´ë“œ: ì œëª© ìŠ¬ë¼ì´ë“œ
- ì¤‘ê°„ ìŠ¬ë¼ì´ë“œ: ì±„ë„ë³„ ë˜ëŠ” ì£¼ì œë³„ í•µì‹¬ ë‚´ìš©
- ë§ˆì§€ë§‰ ìŠ¬ë¼ì´ë“œ: ìš”ì•½ ë° ì‹œì‚¬ì 

**JSON í˜•ì‹:**
```json
{{
  "title": "ì „ì²´ í”„ë ˆì  í…Œì´ì…˜ ì œëª©",
  "date": "ë‚ ì§œ",
  "slides": [
    {{
      "title": "ìŠ¬ë¼ì´ë“œ ì œëª©",
      "content": ["í¬ì¸íŠ¸ 1", "í¬ì¸íŠ¸ 2", "í¬ì¸íŠ¸ 3"],
      "notes": "ë°œí‘œì ë…¸íŠ¸"
    }}
  ]
}}
```

ì¢…í•© ìš”ì•½:
{content}
"""


def generate_slides_data(combined_summary: str, model) -> dict:
    """ìŠ¬ë¼ì´ë“œ êµ¬ì¡° ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    logger.info("ğŸ“Š ìŠ¬ë¼ì´ë“œ ë°ì´í„° ìƒì„± ì¤‘...")

    if model is None:
        return _generate_slides_fallback(combined_summary)

    try:
        prompt = SLIDES_PROMPT.format(content=combined_summary[:25000])
        response = model.generate_content(prompt)
        text = response.text

        # JSON ë¸”ë¡ ì¶”ì¶œ
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0]
        elif "```" in text:
            text = text.split("```")[1].split("```")[0]

        slides_data = json.loads(text.strip())
        logger.info(f"  âœ… {len(slides_data.get('slides', []))}ì¥ ìŠ¬ë¼ì´ë“œ ìƒì„± ì™„ë£Œ")
        return slides_data

    except Exception as e:
        logger.error(f"  âŒ ìŠ¬ë¼ì´ë“œ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
        return _generate_slides_fallback(combined_summary)


def _generate_slides_fallback(combined_summary: str) -> dict:
    """Gemini ì—†ì´ ê¸°ë³¸ ìŠ¬ë¼ì´ë“œ êµ¬ì¡° ìƒì„±"""
    return {
        "title": f"AI/í…Œí¬ ìœ íŠœë¸Œ ì¼ì¼ ì¢…í•© - {datetime.now().strftime('%Y.%m.%d')}",
        "date": datetime.now().strftime("%Yë…„ %mì›” %dì¼"),
        "slides": [
            {
                "title": "ì˜¤ëŠ˜ì˜ AI/í…Œí¬ íŠ¸ë Œë“œ",
                "content": [
                    "ì—¬ëŸ¬ AI ìœ íŠœë¸Œ ì±„ë„ì˜ ìµœì‹  ì½˜í…ì¸ ë¥¼ ì¢…í•©í•©ë‹ˆë‹¤",
                    f"ë¶„ì„ ë‚ ì§œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼')}",
                    "Gemini API í‚¤ ì„¤ì • í›„ ìë™ ìŠ¬ë¼ì´ë“œ ìƒì„± ê°€ëŠ¥",
                ],
                "notes": "ì¸íŠ¸ë¡œ ìŠ¬ë¼ì´ë“œ",
            },
            {
                "title": "âš ï¸ API í‚¤ ë¯¸ì„¤ì •",
                "content": [
                    "GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”",
                    "Google AI Studioì—ì„œ ë¬´ë£Œë¡œ ë°œê¸‰ ê°€ëŠ¥",
                    "https://aistudio.google.com/apikey",
                ],
                "notes": "API í‚¤ ì„¤ì • ì•ˆë‚´",
            },
        ],
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ì¸í¬ê·¸ë˜í”½ ë°ì´í„° ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INFOGRAPHIC_PROMPT = """ì•„ë˜ ìœ íŠœë¸Œ ì±„ë„ ì¢…í•© ìš”ì•½ì„ ê¸°ë°˜ìœ¼ë¡œ, ì¸í¬ê·¸ë˜í”½ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.

**ìš”êµ¬ì‚¬í•­:**
- headline: í•œ ì¤„ í•µì‹¬ íƒ€ì´í‹€
- subheadline: ë¶€ì œëª©
- key_stats: ì£¼ìš” í†µê³„/ìˆ˜ì¹˜ 3~5ê°œ (ê°ê° label, value, icon í¬í•¨)
- main_topics: ì£¼ìš” í† í”½ 3~5ê°œ (ê°ê° title, description, keywords í¬í•¨)  
- trending_keywords: íŠ¸ë Œë”© í‚¤ì›Œë“œ 5~8ê°œ
- takeaway: í•µì‹¬ ì‹œì‚¬ì  í•œ ë¬¸ì¥

**JSON í˜•ì‹:**
```json
{{
  "headline": "í•µì‹¬ íƒ€ì´í‹€",
  "subheadline": "ë¶€ì œëª©",
  "date": "ë‚ ì§œ",
  "key_stats": [
    {{"label": "ë¶„ì„ ì±„ë„", "value": "9ê°œ", "icon": "ğŸ“º"}},
    {{"label": "ì‹ ê·œ ì˜ìƒ", "value": "15ê°œ", "icon": "ğŸ¬"}}
  ],
  "main_topics": [
    {{
      "title": "í† í”½ ì œëª©",
      "description": "ì„¤ëª…",
      "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
    }}
  ],
  "trending_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
  "takeaway": "í•µì‹¬ ì‹œì‚¬ì "
}}
```

ì¢…í•© ìš”ì•½:
{content}
"""


def generate_infographic_data(combined_summary: str, model) -> dict:
    """ì¸í¬ê·¸ë˜í”½ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    logger.info("ğŸ¨ ì¸í¬ê·¸ë˜í”½ ë°ì´í„° ìƒì„± ì¤‘...")

    if model is None:
        return _generate_infographic_fallback()

    try:
        prompt = INFOGRAPHIC_PROMPT.format(content=combined_summary[:20000])
        response = model.generate_content(prompt)
        text = response.text

        if "```json" in text:
            text = text.split("```json")[1].split("```")[0]
        elif "```" in text:
            text = text.split("```")[1].split("```")[0]

        data = json.loads(text.strip())
        logger.info("  âœ… ì¸í¬ê·¸ë˜í”½ ë°ì´í„° ìƒì„± ì™„ë£Œ")
        return data

    except Exception as e:
        logger.error(f"  âŒ ì¸í¬ê·¸ë˜í”½ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")
        return _generate_infographic_fallback()


def _generate_infographic_fallback() -> dict:
    return {
        "headline": "AI/í…Œí¬ ë°ì¼ë¦¬ ì¸ì‚¬ì´íŠ¸",
        "subheadline": f"{datetime.now().strftime('%Yë…„ %mì›” %dì¼')} ìœ íŠœë¸Œ íŠ¸ë Œë“œ",
        "date": datetime.now().strftime("%Yë…„ %mì›” %dì¼"),
        "key_stats": [
            {"label": "ë¶„ì„ ì±„ë„", "value": "9ê°œ", "icon": "ğŸ“º"},
            {"label": "ìƒíƒœ", "value": "API í‚¤ í•„ìš”", "icon": "ğŸ”‘"},
        ],
        "main_topics": [],
        "trending_keywords": ["AI", "ìë™í™”", "íŠ¸ë Œë“œ"],
        "takeaway": "GEMINI_API_KEYë¥¼ ì„¤ì •í•˜ë©´ ìë™ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. ë©”ì¸ ì¢…í•© ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_synthesis(research_results: dict = None) -> dict:
    """ì¢…í•© ì—ì´ì „íŠ¸ ì‹¤í–‰: í†µí•©, íŒŸìºìŠ¤íŠ¸, ìŠ¬ë¼ì´ë“œ, ì¸í¬ê·¸ë˜í”½ ìƒì„±"""
    output_dir = get_today_output_dir()
    model = init_gemini()

    logger.info("=" * 60)
    logger.info("ğŸ“Š ì¢…í•© ì—ì´ì „íŠ¸ ì‹œì‘")
    logger.info("=" * 60)

    # 1. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
    combined = build_combined_summary(output_dir)
    if not combined:
        logger.error("âŒ ì¢…í•©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return {"success": False, "error": "No data to synthesize"}

    # 2. íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    podcast = generate_podcast_script(combined, model)
    podcast_path = output_dir / "podcast_script.md"
    podcast_path.write_text(podcast, encoding="utf-8")
    logger.info(f"ğŸ™ï¸ íŒŸìºìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: {podcast_path}")

    # 3. ìŠ¬ë¼ì´ë“œ ë°ì´í„° ìƒì„±
    slides_data = generate_slides_data(combined, model)
    slides_json_path = output_dir / "slides_data.json"
    slides_json_path.write_text(json.dumps(slides_data, ensure_ascii=False, indent=2), encoding="utf-8")

    # 4. ì¸í¬ê·¸ë˜í”½ ë°ì´í„° ìƒì„±
    infographic_data = generate_infographic_data(combined, model)
    infographic_json_path = output_dir / "infographic_data.json"
    infographic_json_path.write_text(json.dumps(infographic_data, ensure_ascii=False, indent=2), encoding="utf-8")

    return {
        "success": True,
        "output_dir": str(output_dir),
        "files": {
            "combined_summary": str(output_dir / "combined_summary.md"),
            "podcast_script": str(podcast_path),
            "slides_data": str(slides_json_path),
            "infographic_data": str(infographic_json_path),
        },
    }
